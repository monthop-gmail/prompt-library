# ตัวอย่าง AI วิเคราะห์ผิดพลาดเมื่อไม่มี metrics.yaml

> เอกสารนี้แสดงตัวอย่างปัญหาที่เกิดขึ้นเมื่อให้ AI วิเคราะห์ survey โดยไม่มี metrics.yaml ควบคุม

---

## สมมติข้อมูล Survey

แบบสำรวจหลังอบรม "AI for Business" มีคำถาม:
- q1: ความพึงพอใจ (1-5)
- q2: เนื้อหาเข้าใจง่าย (1-5)
- q3: แผนกที่สังกัด
- q4: อายุงาน (ปี)
- q5: ความคิดเห็นเพิ่มเติม (open-ended)

---

## ตัวอย่างที่ 1: Correlation แปลกๆ

**AI วิเคราะห์เอง:**
> "พบว่าอายุงานมี correlation กับความพึงพอใจ (r = -0.42) → พนักงานที่อยู่นานมักไม่พอใจการอบรม"

**ปัญหา:**

| ประเด็น | ทำไมผิด |
|---------|---------|
| Sample size เล็ก | ตอบ 23 คน แต่ AI ไม่บอก → correlation ไม่ reliable |
| ไม่มี causation | อยู่นาน ≠ ไม่ชอบอบรม อาจมีปัจจัยอื่น เช่น เคยเรียนแล้ว |
| ไม่ได้ถามมา | ไม่มีใครขอให้หา correlation นี้ |

**ผลเสีย:** ผู้บริหารอาจเข้าใจผิดว่า "พนักงานเก่าต่อต้านการเปลี่ยนแปลง"

---

## ตัวอย่างที่ 2: สร้าง Metric ใหม่เอง

**AI วิเคราะห์เอง:**
> "คำนวณ 'Training Effectiveness Index' (TEI) = (q1 × 0.4) + (q2 × 0.6) = 3.87"

**ปัญหา:**

| ประเด็น | ทำไมผิด |
|---------|---------|
| น้ำหนัก 0.4, 0.6 มาจากไหน? | AI คิดเอง ไม่มีทฤษฎีรองรับ |
| TEI คืออะไร? | ไม่มีใครนิยามไว้ ไม่มี benchmark |
| เปรียบเทียบไม่ได้ | ครั้งหน้า AI อาจใช้สูตรอื่น |

**ผลเสีย:** องค์กรใช้ TEI = 3.87 ไปรายงาน แต่ไม่รู้ว่าดีหรือไม่ดี

---

## ตัวอย่างที่ 3: สรุปผิดบริบท

**ข้อมูลจริง:**
```
แผนก IT:        ตอบ 15 คน, เฉลี่ย 4.5
แผนก Sales:     ตอบ 3 คน,  เฉลี่ย 2.0
แผนก Marketing: ตอบ 1 คน,  เฉลี่ย 5.0
```

**AI วิเคราะห์เอง:**
> "แผนก Sales มีความพึงพอใจต่ำสุด (2.0) ควรปรับปรุงการอบรมสำหรับทีม Sales โดยเฉพาะ"

**ปัญหา:**

| ประเด็น | ทำไมผิด |
|---------|---------|
| Sample size | Sales ตอบแค่ 3 คน จาก 20 คน → ไม่ represent |
| ไม่รู้บริบท | 3 คนนี้อาจมาสาย พลาดช่วงสำคัญ |
| Marketing 5.0? | คนเดียวให้ 5 ไม่ได้แปลว่าแผนกพอใจ |

**ผลเสีย:** จัดอบรมพิเศษให้ Sales ทั้งที่ปัญหาจริงคือคนไม่มาตอบ survey

---

## ตัวอย่างที่ 4: วิเคราะห์ Open-ended ผิด

**ความคิดเห็นจริง:**
```
"ห้องเย็นมาก"
"เนื้อหาดี แต่เร็วไป"
"ไม่มีที่จอดรถ"
```

**AI วิเคราะห์เอง:**
> "Sentiment Analysis: 67% Negative → ผู้เข้าอบรมส่วนใหญ่ไม่พอใจการอบรม"

**ปัญหา:**

| ประเด็น | ทำไมผิด |
|---------|---------|
| ปนกัน | "ห้องเย็น" กับ "ที่จอดรถ" ไม่เกี่ยวกับเนื้อหา |
| ไม่มี codebook | ไม่ได้กำหนดว่าอะไรคือ positive/negative |
| บิดเบือน | "เนื้อหาดี แต่เร็วไป" = mixed ไม่ใช่ negative |

**ผลเสีย:** สรุปว่าอบรมล้มเหลว ทั้งที่คนชมเนื้อหา แค่บ่นเรื่อง facilities

---

## ถ้ามี metrics.yaml ควบคุม

```yaml
allowed_metrics:
  overall_satisfaction:
    formula: "AVG(q1)"
    min_sample: 10  # ต้องมีอย่างน้อย 10 คน

prohibited:
  - "ห้ามหา correlation โดยไม่ได้รับอนุญาต"
  - "ห้ามสร้าง index/score ใหม่"
  - "ห้ามเปรียบเทียบระหว่างแผนกถ้า n < 10"
  - "ห้ามทำ sentiment analysis โดยไม่มี codebook"
```

**ผลลัพธ์:** AI จะตอบว่า
> "ไม่สามารถเปรียบเทียบระหว่างแผนกได้ เนื่องจาก Sales (n=3) และ Marketing (n=1) มี sample size ต่ำกว่าที่กำหนด (min=10)"

---

## สรุป

| ไม่มี metrics.yaml | มี metrics.yaml |
|-------------------|-----------------|
| AI คิด metrics เอง | ใช้ได้เฉพาะที่กำหนด |
| หา correlation มัวๆ | ต้องได้รับอนุญาตก่อน |
| สรุปจาก n=3 ได้ | บังคับ min sample |
| Sentiment ไม่มี codebook | ต้องมี codebook ก่อน |

> **หลักการ:** AI ควรถูกควบคุมด้วยกฎ ไม่ใช่ด้วยความไว้วางใจ

---

## อ้างอิง

- [AI Survey Steward Framework](./ai_survey_steward_framework.md)
